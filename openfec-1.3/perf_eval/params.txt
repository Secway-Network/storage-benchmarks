################# Performance Evaluation Config file #################

#
# This is the file that gathers all the parameters that control performance
# evaluation tests. It is used both during simulations and during graph
# generation. Feel free to edit this file as appropriate.
#


################################################################################
#	  				tools				       #
################################################################################

# Path to the performance evaluation tool.
# In particular, choose between the Release and Debug versions.
#
fec_tool   ../bin/Release/eperftool
#fec_tool  ../bin/Debug/eperftool

################################################################################
#	  				files				       #
################################################################################

# Name of the trace file.
# At the end of the tests, this file contains all the raw test results, which
# enables their future analysis.
#
trace_file	eperftool_trace.txt

################################################################################
#	  				tests				       #
################################################################################

# Definition: a test is a set of executions of the performance evaluation tool,
# with the same parameters (except the PRNG seed).

# Number of iterations for each test.
# Running the same test several times allows to create graphs with min/average/max
# information which is particularly useful.
#
nb_iterations	100


# Start tests at this offset.
# Useful to increase the accurary of tests without re-calculating the same tests.
offset_iteration	000

# Number of iterations before inserting the results into the d4atabase.
# This is particularly useful in case of very long tests (e.g. that last
# several hours/days), in order to save partial results and get quickly an
# idea of the results (and possibly change parameters if a mistake is found).
#
nb_iterations_for_partial_results	1000

# Set using_threads to true if you want to create threads for running tests in
# parallel.
# By default, the script creates one thread per CPU core. For almost all tests,
# this is highly recommended since it makes simulations much faster. There's an
# exception though, when doing encoding/decoding speed tests. Here a single test
# must be run at a time for maximum accuracy.
#
using_threads true	

# Set using_ml to true if you want to launch tests in such a way to trigger
# Maximum-Likelyhood (ML) decoding.
# This is useful to find the maximum erasure correction capabilities for a given
# LDPC code.
# Warning: if you want to use an SQLite file, using_ml MUST be set to false
# since SQLite does not authorize concurrent access to the file.
#
using_ml true 


################################################################################
#	 		code/codec configuration			       #
################################################################################

#
# General
#

# List of codecs to consider.
#
# 1 | RS
# 3 | LDPC-Staircase
# 5 | LDPC QC from file
# 6 | 1D-2D codec
#
codec	3

 
# List of symbol sizes (in bytes) to consider.
#
symbol_size 1024	

# List of the number of source symbols to consider (in <min> <max> <step> format).

nb_source_symbols 10 100 10
#nb_source_symbols 1024 1024 1

# List of code rates, specified with the k/n values, to consider.
# NB: choose whether the code rate(s) or the number(s) of repair symbols should
# be specified, but do not specify both of them.
#
#code_rate 1/3.5 

# List of the number of repair symbols to consider (in <min> <max> <step> format).
# NB: choose whether the code rate(s) or the number(s) of repair symbols should
# be specified, but do not specify both of them.
#
nb_repair_symbols 20 200 20

#
# Code specific parameters.
#

# With LDPC codes: list of N1 values, i.e. the target number of "1"s per source column
# in the parity check matrix, A.K.A. left degree (in <min> <max> <step> format).
#
ldpc_N1		5 5 2

# XXX: ajout commentaires
#
matrix_mode	binary
#matrix_mode	qc 
#qc_matrix_files  ../tools/qc_tools/qc2mod2sparsematrix/qc_ldpc_r23.bmat
qc_matrix_files  ../tools/qc_tools/qc2mod2sparsematrix/matrix_5_15_40_S.qc

# With QC-LDPC codes: list of expension factors, used to expend the base identity
# circulant matrix into the parity check matrix (in <min> <max> <step> format).
#
#exp_factor	160 160 10


################################################################################
#	  		transmission and loss configuration		       #
################################################################################

# List of transmission types, as defined by the eperftool:
#
#    0		randomly send all source + repair symbols (default)
#    1		randomly send a few source symbols (not necessarily received)
#			+ all repair symbols
#    2		randomly send few src symbols first (always received), then randomly
#			all repair symbols
#    3		randomly send only repair symbols (non systematic)
#    4		sequentially send all src symbols first, then repair symbols
#    5		sequentially send all repair symbols first, then src symbols
#    6		sequentially send all src symbols first, then randomly repair symbols
#    7		sequentially send all repair symbols first, then randomly src symbols
#
tx_type		0

# List of loss types, as defined by the eperftool (at the exception of the step
# parameter):
#	loss <type> [<min> <max> <step>]
# where type is:
#    0		no loss (default)
#    1		simulate random losses using two state markov model
#			n1: loss probability in OK state (integer, default 1)
#			n2: success probability in NOK state (integer, default 25)
#    2		simulate random losses by specifying the target loss probability
#			(floating point value)
#    3		simulate random losses by specifying the target number of losses
#			(rather than probability)
#    4		simulate losses by randomly choosing one packet out of all each steps
#			(overwrites transmission type)
loss			2 51 70  1 
#loss 3 1000


################################################################################
#				database configuration			       #
################################################################################

# Set to true to erase the SQL database when launching a new test.
#
erase_database  true	

# The SQL database can be either a file or an SQL server.
# - If you want to use a file, please install the Perl DBI::SQLite driver
#	before launching the tests. The format is:
#		database file <file>
#	Warning: if you want to use an SQLite file, using_ml MUST be set to false
#	since SQLite does not authorize concurrent access to the file.
#
# - If you want to use a server, the database on the server must exist (but not
#	tables). This is the most powerful solution, since sub-tests can be
#	launched on several machines (for improved simulation speed) and
#	aggregated in the same SQL database. It is also useful if you have a
#	shared high performance simulation machine and a post-analysis desktop
#	that hosts the SQL database.
#	The format is:
#		database server <database_name> <host> <port> <user> <password>
#

database file performance_test.db
#database server test 192.168.1.11 3306 root root

################################################################################
#				graph configuration			       #
################################################################################

# Prefix for graph files.
#
pref_1	test_dec_	

# Suffix for graph files.
#
pref_2	
